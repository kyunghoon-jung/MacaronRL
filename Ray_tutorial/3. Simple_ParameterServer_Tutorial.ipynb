{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 여기서는 Tutorial에서 배운 개념을 이용하여 간단하게 Network parameter를 분산 환경에서 서로 보내고 가져오는 작업을 해보겠습니다. <br>\n",
    "    1. 각 actor는 network을 가지고 있다. \n",
    "    2. 학습을 하면서 일정 간격으로 actor는 learner의 파라미터를 복제해온다.\n",
    "    3. actor와 learner의 중간 매개체 역할을 하는 parameter server가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray \n",
    "import time \n",
    "import numpy as np \n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 17:07:49,343\tINFO services.py:1173 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.0.61',\n",
       " 'raylet_ip_address': '192.168.0.61',\n",
       " 'redis_address': '192.168.0.61:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2021-01-26_17-07-48_899056_97829/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-01-26_17-07-48_899056_97829/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2021-01-26_17-07-48_899056_97829',\n",
       " 'metrics_export_port': 61431,\n",
       " 'node_id': '9973c38a55f9f6d72d9bbc492b199727f3f3bc52'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0461, -0.3639], grad_fn=<AddBackward0>), torch.Size([2]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QNetwork 정의\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hidden=32):\n",
    "        super(QNetwork, self).__init__()\n",
    "\n",
    "        state_size = state_size[0]\n",
    "        self.fc1 = nn.Linear(state_size, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Test\n",
    "state_size = (4, ) \n",
    "action_size = 2 \n",
    "temp_net = QNetwork(state_size, action_size, 32) \n",
    "test = torch.randn(size=(4,)) \n",
    "temp_net(test), temp_net(test).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Parameter_server:\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        \n",
    "    def updates_params(self, model):\n",
    "        self.params.append(model) \n",
    "\n",
    "    def pull_params(self):\n",
    "        return self.params[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Actor:\n",
    "    def __init__(self, params_server, actor_idx):\n",
    "        self.params_server = params_server\n",
    "        self.actor_idx = actor_idx\n",
    "        self.device = 'cpu' # actor는 cpu에서 process가 할당되므로, gpu로 선언하게 되면 작동이 되지 않는다.\n",
    "        self.actor_network = QNetwork((4, ), 12, 64).to(self.device)\n",
    "        \n",
    "    def explore(self):\n",
    "        while 1:\n",
    "            time.sleep(5)\n",
    "            print(\"Explore..\")\n",
    "            self.pull_params()\n",
    "        pass\n",
    "\n",
    "    def pull_params(self):\n",
    "        updated_params = ray.get(self.params_server.pull_params.remote()) \n",
    "        print(\"Parameter Type: \", type(updated_params)) \n",
    "        self.actor_network.load_state_dict(updated_params) \n",
    "        print(f\"Model is updated in actor number_{self.actor_idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner: \n",
    "    def __init__(self, params_server):\n",
    "        self.params_server = params_server\n",
    "        self.device = 'cuda:1' # Learner는 GPU를 써야하므로 CUDA에 할당하기 위해 device를 cuda로 설정\n",
    "        \n",
    "        self.q_behave = QNetwork((4, ), 12, 64).to(self.device)\n",
    "        self.q_target = QNetwork((4, ), 12, 64).to(self.device)\n",
    "        self.q_target.load_state_dict(self.q_behave.state_dict())\n",
    "        self.q_target.eval() \n",
    "\n",
    "    def push_parameters(self):\n",
    "        self.params_server.updates_params.remote(self.q_behave.cpu().state_dict())\n",
    "\n",
    "    def pull_parameters_from_server(self):\n",
    "        return self.params_server.pull_params.remote() \n",
    "    \n",
    "    def train(self):\n",
    "        while 1:\n",
    "            time.sleep(2)\n",
    "            self.push_parameters() \n",
    "            print(\"Learner: Model parameter is sent to Server.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 먼저 하나의 actor에서 한번씩의 메서드가 잘 작동하는지 테스트를 해보겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter sever\n",
    "params_server = Parameter_server.remote()    \n",
    "\n",
    "# learner와 actor 모두 parameter sever를 상속받아 정의합니다. \n",
    "# 그 이유는, learner와 actor는 각각의 방식으로 server에 접근하여 model의 parameter를 주거나 가져오기 때문입니다.\n",
    "learner = Learner(params_server) \n",
    "actor = Actor.remote(params_server, 0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 업데이트하는 것을 임의로 횟수로 잡고, learner의 update 메소드를 그 횟수만큼 실행합니다.\n",
    "iteration = 3\n",
    "for _  in range(iteration): learner.push_parameters() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner에서 server의 parameter를 가지고 오는 것도 되는지 test를 해봅니다. (실제로 learner는 server에서 가지고 올 일은 없습니다.)\n",
    "ray.get(learner.pull_parameters_from_server())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# actor의 explore 메소드를 통해 server에 위에서 learner로 부터 받은 parameter를 가지고 온 후, actor의 모델로 저장이 되는지 테스트 해봅니다.  \n",
    "actor.explore.remote()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막으로 learner가 주기적으로 model parameter를 server에 저장을 하면서,\n",
    "# 동시에 여러 actor가 explore 메소드를 통해 그 parameter를 지속적으로 가지고 오고 update가 되는지 테스트를 해봅니다.\n",
    "\n",
    "params_server = Parameter_server.remote()    \n",
    "learner = Learner(params_server) \n",
    "\n",
    "num_actor = 5\n",
    "for idx in range(num_actor): \n",
    "    actor = Actor.remote(params_server, idx)\n",
    "    actor.explore.remote() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.train() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 성공을 하게 되면 아래와 같은 메세지를 확인할 수 있습니다. <br>\n",
    "    1. Learner: Model parameter is sent to Server.  --> 이 메세지는 learner가 server에 parameter를 보낸 것을 성공했을 시의 메세지입니다.\n",
    "    2. 이 외에, (pid=숫자) 가 붙은 메세지는 각 actor 가 update를 성공했을 때의 메세지입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [실행 예시]\n",
    "    \n",
    "    Learner: Model parameter is sent to Server.\n",
    "    Learner: Model parameter is sent to Server.\n",
    "    (pid=87629) Explore..\n",
    "    (pid=87629) Parameter Type:  <class 'collections.OrderedDict'>\n",
    "    (pid=87629) Model is updated in actor number_3\n",
    "    (pid=87584) Explore..\n",
    "    (pid=87584) Parameter Type:  <class 'collections.OrderedDict'>\n",
    "    (pid=87584) Model is updated in actor number_1\n",
    "    (pid=87630) Explore..\n",
    "    (pid=87630) Parameter Type:  <class 'collections.OrderedDict'>\n",
    "    (pid=87630) Model is updated in actor number_0\n",
    "    (pid=87588) Explore..\n",
    "    (pid=87588) Parameter Type:  <class 'collections.OrderedDict'>\n",
    "    (pid=87588) Model is updated in actor number_4\n",
    "    (pid=87582) Explore..\n",
    "    (pid=87582) Parameter Type:  <class 'collections.OrderedDict'>\n",
    "    (pid=87582) Model is updated in actor number_2\n",
    "    Learner: Model parameter is sent to Server.\n",
    "    Learner: Model parameter is sent to Server.\n",
    "    Learner: Model parameter is sent to Server.\n",
    "    (pid=87629) Explore..\n",
    "    (pid=87629) Parameter Type:  <class 'collections.OrderedDict'>\n",
    "    (pid=87629) Model is updated in actor number_3\n",
    "    (pid=87584) Explore..\n",
    "    (pid=87584) Parameter Type:  <class 'collections.OrderedDict'>\n",
    "    (pid=87584) Model is updated in actor number_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
