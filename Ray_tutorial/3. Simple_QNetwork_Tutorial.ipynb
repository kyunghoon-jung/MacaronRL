{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 여기서는 Tutorial에서 배운 개념을 이용하여 간단하게 Network parameter를 분산 환경에서 서로 복사해오는 작업을 해보겠습니다. <br>\n",
    "    1. 각 actor는 network을 가지고 있다. \n",
    "    2. 학습을 하면서 일정 간격으로 actor는 learner의 파라미터를 복제해온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray \n",
    "import time \n",
    "import numpy as np \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-23 07:45:58,963\tINFO services.py:1173 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.0.61',\n",
       " 'raylet_ip_address': '192.168.0.61',\n",
       " 'redis_address': '192.168.0.61:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2021-01-23_07-45-58_512576_95995/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-01-23_07-45-58_512576_95995/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2021-01-23_07-45-58_512576_95995',\n",
       " 'metrics_export_port': 60564,\n",
       " 'node_id': '25569fa6e591529a16a4161f1adbc687ba4cdd71'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.1507,  0.1949], grad_fn=<AddBackward0>), torch.Size([2]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hidden=32):\n",
    "        super(QNetwork, self).__init__()\n",
    "\n",
    "        state_size = state_size[0]\n",
    "        self.fc1 = nn.Linear(state_size, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "state_size = (4, ) \n",
    "action_size = 2 \n",
    "temp_net = QNetwork(state_size, action_size, 32) \n",
    "test = torch.randn(size=(4,)) \n",
    "temp_net(test), temp_net(test).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor의 역할은 각각 env에서 경험한 것을 buffer에 넘겨주는 역할을 합니다.\n",
    "@ray.remote\n",
    "class Actor:\n",
    "    def __init__(self, \n",
    "                 learner: (\"class: Learner class\"),\n",
    "                 actor_idx: ('int: Actor index'),\n",
    "                 hidden: (\"int: Update frequency of learner's q_behave network\"), \n",
    "                 device: (\"int: Cuda device number\")):\n",
    "\n",
    "        self.learner = learner # ray를 통해 공유하는 learner class입니다.\n",
    "        self.device = device\n",
    "        self.actor_idx = actor_idx\n",
    "\n",
    "        # Network parameters\n",
    "        self.state_dim = (16, )\n",
    "        self.action_dim = 3\n",
    "        self.q_behave = QNetwork(self.state_dim, self.action_dim, hidden).to(self.device)\n",
    "\n",
    "    def explore(self):\n",
    "        print(\"exploration start..\")\n",
    "        while 1:\n",
    "            time.sleep(3)\n",
    "            self.get_weights()\n",
    "            print('updates done.')\n",
    "\n",
    "    def get_weights(self):\n",
    "        weight_copy = self.learner.return_weights.remote()\n",
    "        weight_copy = ray.get(weight_copy)\n",
    "        print(type(weight_copy), self.actor_idx)\n",
    "        self.q_behave.load_state_dict(weight_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공유 Buffer를 통해 학습을 진행하는 Learner를 정의합니다. \n",
    "# Learner는 buffer에 있는 샘플을 이용하여 network parameter를 업데이트를 하며, agent에게 network weight을 전달합니다.\n",
    "\n",
    "@ray.remote\n",
    "class Learner:\n",
    "    def __init__(self, \n",
    "                 hidden: (\"int: Update frequency of learner's q_behave network\"), \n",
    "                 device: (\"int: Cuda device number\")):\n",
    "        \n",
    "        self.state_dim = (16, )\n",
    "        self.action_dim = 3\n",
    "        self.device = device\n",
    "        \n",
    "        self.q_behave = QNetwork(self.state_dim, self.action_dim, hidden).to(self.device)\n",
    "        self.q_target = QNetwork(self.state_dim, self.action_dim, hidden).to(self.device)\n",
    "        self.q_target.load_state_dict(self.q_behave.state_dict())\n",
    "        self.q_target.eval()\n",
    "\n",
    "    def return_weights(self):\n",
    "        return self.q_target.state_dict() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 32\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "\n",
    "learner = Learner.remote(hidden, device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=96117)\u001b[0m exploration start..\n",
      "\u001b[2m\u001b[36m(pid=96123)\u001b[0m exploration start..\n",
      "\u001b[2m\u001b[36m(pid=96122)\u001b[0m exploration start..\n",
      "\u001b[2m\u001b[36m(pid=96168)\u001b[0m exploration start..\n",
      "\u001b[2m\u001b[36m(pid=96170)\u001b[0m exploration start..\n",
      "\u001b[2m\u001b[36m(pid=96171)\u001b[0m exploration start..\n",
      "\u001b[2m\u001b[36m(pid=96116)\u001b[0m exploration start..\n",
      "\u001b[2m\u001b[36m(pid=96118)\u001b[0m exploration start..\n",
      "\u001b[2m\u001b[36m(pid=96125)\u001b[0m exploration start..\n",
      "\u001b[2m\u001b[36m(pid=96124)\u001b[0m exploration start..\n",
      "\u001b[2m\u001b[36m(pid=96131)\u001b[0m exploration start..\n",
      "\u001b[2m\u001b[36m(pid=96110)\u001b[0m exploration start..\n",
      "\u001b[2m\u001b[36m(pid=96120)\u001b[0m exploration start..\n",
      "\u001b[2m\u001b[36m(pid=96113)\u001b[0m exploration start..\n",
      "\u001b[2m\u001b[36m(pid=96133)\u001b[0m exploration start..\n",
      "\u001b[2m\u001b[36m(pid=96114)\u001b[0m exploration start..\n",
      "\u001b[2m\u001b[36m(pid=96117)\u001b[0m <class 'collections.OrderedDict'> 9\n",
      "\u001b[2m\u001b[36m(pid=96117)\u001b[0m updates done.\n",
      "\u001b[2m\u001b[36m(pid=96168)\u001b[0m <class 'collections.OrderedDict'> 4\n",
      "\u001b[2m\u001b[36m(pid=96168)\u001b[0m updates done.\n",
      "\u001b[2m\u001b[36m(pid=96170)\u001b[0m <class 'collections.OrderedDict'> 1\n",
      "\u001b[2m\u001b[36m(pid=96170)\u001b[0m updates done.\n",
      "\u001b[2m\u001b[36m(pid=96171)\u001b[0m <class 'collections.OrderedDict'> 0\n",
      "\u001b[2m\u001b[36m(pid=96171)\u001b[0m updates done.\n",
      "\u001b[2m\u001b[36m(pid=96123)\u001b[0m <class 'collections.OrderedDict'> 2\n",
      "\u001b[2m\u001b[36m(pid=96123)\u001b[0m updates done.\n",
      "\u001b[2m\u001b[36m(pid=96122)\u001b[0m <class 'collections.OrderedDict'> 3\n",
      "\u001b[2m\u001b[36m(pid=96122)\u001b[0m updates done.\n",
      "\u001b[2m\u001b[36m(pid=96116)\u001b[0m <class 'collections.OrderedDict'> 5\n",
      "\u001b[2m\u001b[36m(pid=96116)\u001b[0m updates done.\n",
      "\u001b[2m\u001b[36m(pid=96118)\u001b[0m <class 'collections.OrderedDict'> 12\n",
      "\u001b[2m\u001b[36m(pid=96118)\u001b[0m updates done.\n",
      "\u001b[2m\u001b[36m(pid=96131)\u001b[0m <class 'collections.OrderedDict'> 6\n",
      "\u001b[2m\u001b[36m(pid=96131)\u001b[0m updates done.\n",
      "\u001b[2m\u001b[36m(pid=96125)\u001b[0m <class 'collections.OrderedDict'> 10\n",
      "\u001b[2m\u001b[36m(pid=96125)\u001b[0m updates done.\n",
      "\u001b[2m\u001b[36m(pid=96124)\u001b[0m <class 'collections.OrderedDict'> 8\n",
      "\u001b[2m\u001b[36m(pid=96124)\u001b[0m updates done.\n",
      "\u001b[2m\u001b[36m(pid=96110)\u001b[0m <class 'collections.OrderedDict'> 11\n",
      "\u001b[2m\u001b[36m(pid=96110)\u001b[0m updates done.\n",
      "\u001b[2m\u001b[36m(pid=96120)\u001b[0m <class 'collections.OrderedDict'> 7\n",
      "\u001b[2m\u001b[36m(pid=96120)\u001b[0m updates done.\n",
      "\u001b[2m\u001b[36m(pid=96133)\u001b[0m <class 'collections.OrderedDict'> 13\n",
      "\u001b[2m\u001b[36m(pid=96133)\u001b[0m updates done.\n",
      "\u001b[2m\u001b[36m(pid=96114)\u001b[0m <class 'collections.OrderedDict'> 15\n",
      "\u001b[2m\u001b[36m(pid=96114)\u001b[0m updates done.\n",
      "\u001b[2m\u001b[36m(pid=96113)\u001b[0m <class 'collections.OrderedDict'> 14\n",
      "\u001b[2m\u001b[36m(pid=96113)\u001b[0m updates done.\n"
     ]
    }
   ],
   "source": [
    "num_actors = 16 # actor의 개수\n",
    "\n",
    "# num_actors 개수만큼 선언하고, explore 실행. actor라는 변수가 계속 중복이 되지만 실행은 잘 된다.\n",
    "for actor_idx in range(num_actors):\n",
    "    actor = Actor.remote(learner, actor_idx, hidden, device)\n",
    "    actor.explore.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
