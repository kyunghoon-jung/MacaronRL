{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference Link\n",
    "\n",
    "    해당 노트북은 아래의 reference를 참고하면서 작성하였으며, 참고 링크에는 좀 더 정성적인 특징을 기술해놓았습니다.\n",
    "    This notebook is written with the following references, which state more detailed characteristics of the Ray package.\n",
    "    \n",
    "    https://data-newbie.tistory.com/415,\n",
    "    https://towardsdatascience.com/modern-parallel-and-distributed-python-a-quick-tutorial-on-ray-99f8d70369b8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install ray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://drive.google.com/uc?id=1HBbLD02L-o4_oOLQxEx6MvKKiFcbEBhP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ray는 사용하기 위해서 import 뿐만 아니라, ray.init()이 필요합니다.\n",
    "#### To use Ray, one needs to write as follows after importing Ray module for the initialization. \n",
    "    import ray\n",
    "    ray.init() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-22 14:43:19,392\tINFO services.py:1173 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.0.61',\n",
       " 'raylet_ip_address': '192.168.0.61',\n",
       " 'redis_address': '192.168.0.61:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2021-03-22_14-43-18_969694_9821/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-03-22_14-43-18_969694_9821/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2021-03-22_14-43-18_969694_9821',\n",
       " 'metrics_export_port': 57688,\n",
       " 'node_id': '66b4dc21aff7590495047f388519733086cbbadc'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실행 후 localhost: port번호 가 출력되는 것을 볼 수 있는데요, 이 주소는 resource가 어떤 식으로 쓰이고 있는지 보여줍니다.\n",
    "#### After excuting it, one can see the address as \"Local IP address: ####\". This is where one can monitor the status of the server's resourse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" For GPU users\\n\\nimport torch\\n\\nray.init(num_gpus=2) # 'num_gpus' in ray.init() means the number of gpus to be used in the whole producedures \\n\\n@ray.remote(num_gpus=2)  # 'num_gpus' in ray.remote() means the ratio of gpu memory to be occupied when the corresponding class('GPUActor' in this case) is called. \\nclass GPUActor(object):\\n    def __init__(self):\\n        a = torch.nn.Linear(10, 10).cuda()\\n        b = torch.ones(1,10).cuda()\\n        print(a(b))\\n\\n# The four tasks created here can execute concurrently.\\n[GPUActor.remote() for _ in range(2)]\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For GPU users\n",
    "''' \n",
    "\n",
    "import torch\n",
    "\n",
    "ray.init(num_gpus=2) # 'num_gpus' in ray.init() means the number of gpus to be used in the whole producedures \n",
    "\n",
    "@ray.remote(num_gpus=2)  # 'num_gpus' in ray.remote() means the ratio of gpu memory to be occupied when the corresponding class('GPUActor' in this case) is called. \n",
    "class GPUActor(object):\n",
    "    def __init__(self):\n",
    "        a = torch.nn.Linear(10, 10).cuda()\n",
    "        b = torch.ones(1,10).cuda()\n",
    "        print(a(b))\n",
    "\n",
    "# The four tasks created here can execute concurrently.\n",
    "[GPUActor.remote() for _ in range(2)]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 지금부터는 구체적인 활용법을 다루어보겠습니다.\n",
    "#### 병렬처리를 하고자하는 함수를 @ray.remote라는 decoration을 통해 다음과 같이 선언합니다.\n",
    "\n",
    "    @ray.remote\n",
    "    def f(x):\n",
    "        time.sleep(5)\n",
    "        return x * x\n",
    "\n",
    "    이렇게 선언하고 나면, 이제 함수는 \n",
    "    \n",
    "    함수명.remote()\n",
    "\n",
    "    와 같이 .remote()를 붙여야만 호출할 수 있게 됩니다. \n",
    "    여기서, remote()는 task를 하나의 thread에 던져주는 역할을 하고, 그 메소드가 실행이 완료될 때까지 기다리지 않습니다.\n",
    "    따라서 코드를 실행시켜나갈 때 remote() 가 있는 라인은 .remote()로 실행시킨 라인에서 결과를 얻지 못해도 바로 다음 줄로 넘어갑니다. 즉, \n",
    "\n",
    "    results = []\n",
    "    for i in range(10):\n",
    "        results.append(f.remote(i))\n",
    "\n",
    "    이렇게 실행하면 함수f의 결과를 기다리지 않고, 그냥 thread에 던져놓고 바로바로 반복문을 수행하기 때문에 순식간에 10번의 loop이 끝납니다.\n",
    "\n",
    "    ray.get(results)\n",
    "    \n",
    "    결과를 얻기 위해서는 ray.get()를 이용하여야 하는데요. 위와 같이 실행하면, 모든 thread의 실행이 끝났을 때 출력을 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병렬 처리하고 싶은 함수가 있으면, 아래의 데코레이터로 지정하면 병렬 모드로 쓸 수 있습니다. \n",
    "\n",
    "@ray.remote\n",
    "def f(x):\n",
    "    time.sleep(5)\n",
    "    return x * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16]\n",
      "총 걸린 시간:  5.03107476234436\n"
     ]
    }
   ],
   "source": [
    "# number of workers 변수를 통해서 위에서 선언한 함수를 몇 개를 동시에 실행시킬지 정하고 있습니다.\n",
    "\n",
    "number_of_workers = 5\n",
    "\n",
    "\n",
    "tic = time.time()\n",
    "results = [f.remote(i) for i in range(number_of_workers)]\n",
    "print(ray.get(results)) \n",
    "\n",
    "\n",
    "print(\"총 걸린 시간: \", time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_workers = 40\n",
    "\n",
    "tic = time.time()\n",
    "results = [f.remote(i) for i in range(number_of_workers)]\n",
    "print(ray.get(results))\n",
    "print(\"총 걸린 시간: \", time.time()-tic)\n",
    "\n",
    "# 원래 병렬처리가 없었다면, 40번 함수가 호출되었으므로 40*5=200 초가 걸렸겠지만, 여러 thread가 동시에 병렬 처리하여 훨씬 빠르게 수행되는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 또한 Ray는 특정 데이터를 공유 메모리에 저장하고, 그 데이터를 thread 간에 공유가 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "걸린시간(s):  8.013531684875488\n"
     ]
    }
   ],
   "source": [
    "# ray.put 함수를 이용해서 공유하고자 하는 객체를 지정할 수 있습니다.\n",
    "# 이렇게 지정한 객체는 여러 함수가 접근하여 필요한 처리를 할 수 있고, 따라서 메모리를 매우 효율적으로 쓸 수 있다는 장점이 있습니다.\n",
    "\n",
    "import numpy as np\n",
    "import psutil\n",
    "import scipy.signal\n",
    "\n",
    "@ray.remote\n",
    "def f(image, random_filter):\n",
    "    # Do some image processing.\n",
    "    return scipy.signal.convolve2d(image, random_filter)[::5, ::5]\n",
    "\n",
    "num_of_workers = 12\n",
    "filters = [np.random.normal(size=(4, 4)) for _ in range(num_of_workers)] \n",
    "\n",
    "tic = time.time() \n",
    "for _ in range(10):\n",
    "    image = np.zeros((3000, 3000))\n",
    "    image_id = ray.put(image)  # 공유메모리에 올리는 선언\n",
    "    results = [f.remote(image_id, filters[i]) for i in range(num_of_workers)]\n",
    "    ray.get(results)\n",
    "print(\"걸린시간(s): \", time.time() - tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시간을 비교하기 위해서 이번에는 ray 없이 for문을 수행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(image, random_filter):\n",
    "    return scipy.signal.convolve2d(image, random_filter)[::5, ::5]\n",
    "\n",
    "num_of_workers = 4\n",
    "filters = [np.random.normal(size=(4, 4)) for _ in range(num_of_workers)] \n",
    "\n",
    "tic = time.time() \n",
    "for _ in range(10):\n",
    "    image = np.zeros((3000, 3000))\n",
    "    results = [f(image, filters[i]) for i in range(num_of_workers)]\n",
    "print(\"걸린시간(s): \", time.time() - tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정확히 num_of_workes의 배수만큼 느려진 것은 아니지만 확연한 차이를 확인할 수 있는데\n",
    "#### 특히 image라는 배열 변수 복제할 필요없이, 여러 thread가 ray.put() 메소드로 쉽게 공유하고 access할 수 있다는 점은 눈여겨볼 만한 포인트입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote \n",
    "def create_matrix(size, num): \n",
    "    time.sleep(num) \n",
    "    return np.random.normal(size=size) \n",
    "\n",
    "@ray.remote \n",
    "def multiply_matrices(x, y): \n",
    "    return np.dot(x, y)\n",
    "\n",
    "x_id = create_matrix.remote([1000, 1000], 6)\n",
    "y_id = create_matrix.remote([1000, 1000], 2)\n",
    "z_id = multiply_matrices.remote(x_id, y_id)\n",
    "\n",
    "# 아래의 걸린 시간을 보면, x가 늦게 끝나므로 x가 종료되는 시점에 z가 계산됨을 알 수 있습니다. \n",
    "tic = time.time()\n",
    "z = ray.get(z_id)\n",
    "print(\"걸린시간(s): \", time.time() - tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이번에는 다음과 같은 연산 그래프를 실현해보겠습니다. <br>\n",
    "    왼쪽 그림과 오른쪽 그림의 연산 속도는 얼마나 차이가 날까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://drive.google.com/uc?id=1HG_mnwXO4mtG-ih2Kr3Kdd_MfNx0Esvq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result 36\n",
      "걸린시간(s):  7.171598672866821\n",
      "result 36\n",
      "걸린시간(s):  3.0769569873809814\n"
     ]
    }
   ],
   "source": [
    "# 위의 그림에 있는 연산처리 순서대로 코드를 테스트 해본 것.\n",
    "\n",
    "@ray.remote\n",
    "def add(x, y):\n",
    "    time.sleep(1)\n",
    "    return x + y\n",
    "\n",
    "# 먼저 왼쪽에 있는 흐름대로 add 연산을 해보겠습니다. 이 방식은 더하는 숫자가 n개 일 때, O(n)의 계산량을 필요로 합니다.\n",
    "tic = time.time()\n",
    "id1 = add.remote(1, 2)\n",
    "id2 = add.remote(id1, 3)\n",
    "id3 = add.remote(id2, 4)\n",
    "id4 = add.remote(id3, 5)\n",
    "id5 = add.remote(id4, 6)\n",
    "id6 = add.remote(id5, 7)\n",
    "id7 = add.remote(id6, 8)\n",
    "result = ray.get(id7)\n",
    "print(\"Result: \", result)\n",
    "print(\"걸린시간(s): \", time.time() - tic)\n",
    "\n",
    "# 먼저 왼쪽에 있는 흐름대로 add 연산을 해보겠습니다. 이 방식은 더하는 숫자가 n개 일 때, O(log(n))의 계산량이 들기 때문에,\n",
    "# 위의 방법보다 n이 커질 수록 매우 유용한 방법입니다.\n",
    "\n",
    "tic = time.time()\n",
    "id1 = add.remote(1, 2)\n",
    "id2 = add.remote(3, 4)\n",
    "id3 = add.remote(5, 6)\n",
    "id4 = add.remote(7, 8)\n",
    "id5 = add.remote(id1, id2)\n",
    "id6 = add.remote(id3, id4)\n",
    "id7 = add.remote(id5, id6)\n",
    "result = ray.get(id7)\n",
    "print(\"Result: \", result)\n",
    "print(\"걸린시간(s): \", time.time() - tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 위와 동일한 연산. 좀 더 간단하게 표현한 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 느린 것\n",
    "values = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "while len(values) > 1:\n",
    "    values = [add.remote(values[0], values[1])] + values[2:]\n",
    "result = ray.get(values[0])\n",
    "\n",
    "# 빠른 것. \n",
    "# 코딩 요령: 리스트를 자르고, ray.remote를 리스트의 뒤로 넘긴 것.\n",
    "values = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "while len(values) > 1:\n",
    "    values = values[2:] + [add.remote(values[0], values[1])] \n",
    "result = ray.get(values[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이번에는 class를 ray를 이용하여 병렬로 처리해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Counter(object):\n",
    "    def __init__(self):\n",
    "        self.n = 0\n",
    "\n",
    "    def increment(self, num):\n",
    "        time.sleep(5)\n",
    "        self.n += (num**3)\n",
    "        print(self.n)\n",
    "\n",
    "    def read(self):\n",
    "        return self.n\n",
    "\n",
    "number_of_workers = 4\n",
    "\n",
    "tic = time.time()\n",
    "counters = [Counter.remote() for i in range(number_of_workers)]\n",
    "[cnt_class.increment.remote(idx) for idx, cnt_class in enumerate(counters)]\n",
    "results = [c.read.remote() for c in counters]\n",
    "print(ray.get(results))\n",
    "print(\"걸린시간(s): \", time.time() - tic)\n",
    "\n",
    "number_of_workers = 12\n",
    "\n",
    "tic = time.time()\n",
    "counters = [Counter.remote() for i in range(number_of_workers)]\n",
    "[c.increment.remote(idx) for idx, c in enumerate(counters)]\n",
    "results = [c.read.remote() for c in counters]\n",
    "print(ray.get(results))\n",
    "print(\"걸린시간(s): \", time.time() - tic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiprocessing 패키지는 어떤 output이 어느 thread에서 온 것인지 확인하려면 별도의 매소드로 확인해주어야 했지만, \n",
    "#### ray는 PID를 자체적으로 함께 출력해주기 때문에 어떤 thread에서 나온 출력인지 쉽게 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메세지를 저장하고 불러오는 class를 선언\n",
    "@ray.remote\n",
    "class MessageActor(object):\n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "    \n",
    "    def add_message(self, message):\n",
    "        self.messages.append(message)\n",
    "        \n",
    "    def get_and_clear_messages(self):\n",
    "        messages = self.messages\n",
    "#         time.sleep(0.2)\n",
    "        self.messages = []\n",
    "        return messages\n",
    "\n",
    "# worker라는 함수는 메세지를 받아서 저장해주는 역할을 합니다.\n",
    "@ray.remote\n",
    "def worker(message_actor, j):\n",
    "    for i in range(100):\n",
    "        time.sleep(np.random.uniform(0.5, 1)) # 의도적으로 random 하게 시간을 기다리게 하여, 각 worker가 서로 다른 시간에 랜덤하게 message_actor에 접근하도록 해보았습니다.\n",
    "        message_actor.add_message.remote(\"Message {} from worker {}.\".format(i, j))\n",
    "        \n",
    "# 메세지 class 의 인스턴스 생성\n",
    "message_actor = MessageActor.remote()\n",
    "\n",
    "# 위에서 생성한 클레스에 10개의 병렬 worker를 할당해보겠습니다.\n",
    "# 각 worker는 1개의 클래스 메서드(여기서는 message_actor의 add_message 메서드)를 실행하여 self.messages에 메세지를 계속 append합니다. \n",
    "num_of_workers = 10\n",
    "[worker.remote(message_actor, j) for j in range(num_of_workers)]\n",
    "\n",
    "# for문을 돌면서 계속해서 massage를 가져옵니다.\n",
    "for _ in range(100):\n",
    "    # 아래줄 처럼 실행하면 에러가 납니다. 그 이유는 @ray.remote 로 decorate이 되었으면 메소드를 실행할 때, .remote()를 뒤에 붙여야하기 때문입니다.\n",
    "    # new_messages = message_actor.get_and_clear_messages()\n",
    "    # \n",
    "    # 올바른 예시\n",
    "    new_messages = ray.get(message_actor.get_and_clear_messages.remote())\n",
    "    print(\"New messages:\", new_messages)\n",
    "    time.sleep(1)\n",
    "\n",
    "# 위의 명령어를 실행하면 다음과 비슷한 출력이 나옵니다.\n",
    "# New messages: []\n",
    "# New messages: ['Message 0 from worker 1.', 'Message 0 from worker 0.']\n",
    "# New messages: ['Message 0 from worker 2.', 'Message 1 from worker 1.', 'Message 1 from worker 0.', 'Message 1 from worker 2.']\n",
    "# New messages: ['Message 2 from worker 1.', 'Message 2 from worker 0.', 'Message 2 from worker 2.']\n",
    "# New messages: ['Message 3 from worker 2.', 'Message 3 from worker 1.', 'Message 3 from worker 0.']\n",
    "# New messages: ['Message 4 from worker 2.', 'Message 4 from worker 0.', 'Message 4 from worker 1.']\n",
    "# New messages: ['Message 5 from worker 2.', 'Message 5 from worker 0.', 'Message 5 from worker 1.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 위 코드를 통해, ray를 이용하여 분산 RL을 구현해본다고 했을 때 다음을 생각해볼 수 있습니다. \n",
    "\n",
    "    위에서 class는 두 가지 메소드를 가진다.\n",
    "\n",
    "    1) add_message와 2) get_and_clear_messages 로써 2개.\n",
    "    \n",
    "    한편, worker 함수는 message_actor라는 클래스의 add_message 메소드를 실행하는 함수이며, 계속해서 self.messege라는 클래스 변수를 변동시켰다.\n",
    "\n",
    "    그리고 코드 아래 부분에서는 self.messege라는 변수에 새로운 메세지를 append하는 작업이 계속 되고 있으면서 동시에, \n",
    "\n",
    "    클래스의 다른 메소드인 get_and_clear_messages를 실행하였다. 즉 다시말해서 다른 함수가 계속해서 새로운 '쓰기'작업을 하는 중에 이와는 또 다른 함수가 똑같은 변수에 접근하여 '읽기'를 수행할 수 있는 것.\n",
    "\n",
    "    이는 바로, 강화학습의 Q-learning 기법에서 많이 쓰이는 Replay Buffer를 여러 agent가 공유하고, 쓰기와 읽기를 동시에 할 수 있음을 시사한다.\n",
    "\n",
    "    클래스의 다른 메소드를 동시에 실행하는 것까지는 놀라운 일이 아닐지라도,\n",
    "\n",
    "    self.messege 라는 변수를 서로 다른 함수끼리 공유하면서 지속적으로 append하고 accessing하는 것을 실시간으로, 비교적 간단한 문법으로 가능하다는 것은 큰 장점이라고 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "num_of_workers = 4\n",
    "\n",
    "@ray.remote\n",
    "class StreamingPrefixCount(object):\n",
    "    def __init__(self):\n",
    "        self.prefix_count = defaultdict(int)\n",
    "        self.popular_prefixes = set()\n",
    "\n",
    "    def add_document(self, document):\n",
    "        for word in document:\n",
    "            for i in range(1, len(word)):\n",
    "                prefix = word[:i]\n",
    "                self.prefix_count[prefix] += 1\n",
    "                if self.prefix_count[prefix] > 3:\n",
    "                    self.popular_prefixes.add(prefix)\n",
    "\n",
    "    def get_popular(self):\n",
    "        return self.popular_prefixes\n",
    "\n",
    "streaming_actors = [StreamingPrefixCount.remote() for _ in range(num_of_workers)]\n",
    "\n",
    "tic = time.time()\n",
    "for i in range(num_of_workers * 10):\n",
    "    document = [np.random.bytes(20) for _ in range(30000)]\n",
    "    streaming_actors[i % num_of_workers].add_document.remote(document)\n",
    "\n",
    "results = ray.get([actor.get_popular.remote() for actor in streaming_actors])\n",
    "popular_prefixes = set()\n",
    "for prefixes in results:\n",
    "    popular_prefixes |= prefixes\n",
    "print(\"걸린시간(s): \", time.time() - tic)\n",
    "print(popular_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "num_of_workers = 4\n",
    "\n",
    "class StreamingPrefixCount(object):\n",
    "    def __init__(self):\n",
    "        self.prefix_count = defaultdict(int)\n",
    "        self.popular_prefixes = set()\n",
    "\n",
    "    def add_document(self, document):\n",
    "        for word in document:\n",
    "            for i in range(1, len(word)):\n",
    "                prefix = word[:i]\n",
    "                self.prefix_count[prefix] += 1\n",
    "                if self.prefix_count[prefix] > 3:\n",
    "                    self.popular_prefixes.add(prefix)\n",
    "\n",
    "    def get_popular(self):\n",
    "        return self.popular_prefixes\n",
    "\n",
    "streaming_actors = [StreamingPrefixCount() for _ in range(num_of_workers)]\n",
    "\n",
    "tic = time.time()\n",
    "for i in range(num_of_workers * 10):\n",
    "    document = [np.random.bytes(20) for _ in range(30000)]\n",
    "    streaming_actors[i % num_of_workers].add_document(document)\n",
    "\n",
    "results = [actor.get_popular() for actor in streaming_actors]\n",
    "popular_prefixes = set()\n",
    "for prefixes in results:\n",
    "    popular_prefixes |= prefixes\n",
    "print(\"걸린시간(s): \", time.time() - tic)\n",
    "print(popular_prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 딥러닝 모델의 평가도 Ray로 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import ray\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "num_cpus = psutil.cpu_count(logical=False)\n",
    "ray.init(num_cpus=num_cpus)\n",
    "filename = '/tmp/model'\n",
    "\n",
    "@ray.remote\n",
    "class Model(object):\n",
    "    def __init__(self, i):\n",
    "        # Pin the actor to a specific core if we are on Linux to prevent\n",
    "        # contention between the different actors since TensorFlow uses\n",
    "        # multiple threads.\n",
    "        if sys.platform == 'linux':\n",
    "            psutil.Process().cpu_affinity([i])\n",
    "        # Load the model and some data.\n",
    "        self.model = tf.keras.models.load_model(filename)\n",
    "        mnist = tf.keras.datasets.mnist.load_data()\n",
    "        self.x_test = mnist[1][0] / 255.0\n",
    "\n",
    "    def evaluate_next_batch(self):\n",
    "        # Note that we reuse the same data over and over, but in a\n",
    "        # real application, the data would be different each time.\n",
    "        return self.model.predict(self.x_test)\n",
    "\n",
    "actors = [Model.remote(i) for i in range(num_cpus)]\n",
    "\n",
    "# Parallelize the evaluation of some test data.\n",
    "for j in range(10):\n",
    "    results = ray.get([actor.evaluate_next_batch.remote() for actor in actors])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 특징\n",
    "    \n",
    "    위의 for문을 보면, actor가 총 10번 선언이 되는 것을 볼 수 있습니다. 일반적인 상황이라면 10번 model을 load했을텐데,\n",
    "    Ray는 액터의 생성자에서 모델을 한 번만 로드하여 이 모델을 actor끼리 공유합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 기본 패키지인 multiprocessing 패키지를 이용한 것\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import psutil\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "num_cpus = psutil.cpu_count(logical=False)\n",
    "\n",
    "filename = '/tmp/model'\n",
    "\n",
    "def evaluate_next_batch(i):\n",
    "    # Pin the process to a specific core if we are on Linux to prevent\n",
    "    # contention between the different processes since TensorFlow uses\n",
    "    # multiple threads.\n",
    "    if sys.platform == 'linux':\n",
    "        psutil.Process().cpu_affinity([i])\n",
    "    model = tf.keras.models.load_model(filename)\n",
    "    mnist = tf.keras.datasets.mnist.load_data()\n",
    "    x_test = mnist[1][0] / 255.0\n",
    "    return model.predict(x_test)\n",
    "\n",
    "pool = Pool(num_cpus)\n",
    "\n",
    "for _ in range(10):\n",
    "    pool.map(evaluate_next_batch, range(num_cpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
