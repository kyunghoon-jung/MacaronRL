#### Welcome! This repo contains reinforcement learning algorithms.

- 2020.11.11 Confirmed for the performances for several atari games such as Q-Bert, Seaquest, Boxing, Pong, etc.  

- I'll write up the detailed comments in all the codes soon. 

- Colab online codes.

   Discrete action space: 불연속 행동 공간<br>
   Continous action space: 연속 행동 공간<br>
   REINFOCE, Baseline, Actor-Critic: Sutton textbook의 Policy Gradient chapter의 알고리즘<br>
   Colab에서 열기: 오른쪽 colab 이미지 클릭

    - REINFORCE in Discrete action space.  [![REINFORCE in Discrete action space](https://user-images.githubusercontent.com/56760035/104275255-cb4d0b00-54e5-11eb-9501-afa6ead99c23.png)](https://colab.research.google.com/github/kyunghoon-jung/MacaronRL/blob/main/Policy_Based/REINFORCE/1.%20DiscreteREINFORCE.ipynb)

    - REINFORCE in Continuous action space.  [![REINFORCE in Continuous action space](https://user-images.githubusercontent.com/56760035/104275255-cb4d0b00-54e5-11eb-9501-afa6ead99c23.png)](https://colab.research.google.com/github/kyunghoon-jung/MacaronRL/blob/main/Policy_Based/REINFORCE/2.%20ContinuousREINFORCE.ipynb)

    - REINFORCE with baseline in Discrete action space.  [![REINFORCE with baseline in Discrete action space](https://user-images.githubusercontent.com/56760035/104275255-cb4d0b00-54e5-11eb-9501-afa6ead99c23.png)](https://colab.research.google.com/github/kyunghoon-jung/MacaronRL/blob/main/Policy_Based/REINFORCE/3.%20DiscreteREINFORCEwithBaseline.ipynb)

    - Actor-Critic in Discrete action space.  [![Actor Critic in Discrete action space](https://user-images.githubusercontent.com/56760035/104275255-cb4d0b00-54e5-11eb-9501-afa6ead99c23.png)](https://colab.research.google.com/github/kyunghoon-jung/MacaronRL/blob/main/Policy_Based/Actor_Critic/4.%20DiscreteActorCritic.ipynb)

    - Actor-Critic in Continous action space.  [![Actor Critic in Continous action space](https://user-images.githubusercontent.com/56760035/104275255-cb4d0b00-54e5-11eb-9501-afa6ead99c23.png)](https://colab.research.google.com/github/kyunghoon-jung/MacaronRL/blob/main/Policy_Based/Actor_Critic/5.%20ContinuousActorCritic.ipynb)

- Ray Pararell python package Totorial series.

   - Ray Tutorial  [![Ray_tutorial](이미지링크)](노트북링크)
   - Simple ReplayBuffer Tutorial [![ReplayBuffer](이미지링크)](노트북링크)
   - Simple ParameterServer Tutorial [![ParameterServer](https://user-images.githubusercontent.com/56760035/106245884-987a7500-6250-11eb-8459-a5f6b047a735.png)](http://colab.research.google.com/github/kyunghoon-jung/MacaronRL/blob/main/Ray_tutorial/3.%20Simple_ParameterServer_Tutorial.ipynb)
   - Visualization with Ray [![Visualization](이미지링크)](노트북링크)
   - Distributed DQN (with manipulting update steps)[![Distributed DQN manipulting](이미지링크)](노트북링크)
   - Distributed DQN [![Distributed DQN](이미지링크)](노트북링크)

- All the algorithms here are written with the help of following references.

    - Sutton - Reinforcement Learning Textbook 2nd ed.
    - https://github.com/Curt-Park/rainbow-is-all-you-need  
    - https://github.com/MrSyee/pg-is-all-you-need  
    - https://github.com/ShangtongZhang/DeepRL  
    - https://github.com/sfujim
    - https://github.com/yandexdataschool/Practical_RL  
    - https://github.com/seungeunrho/minimalRL
